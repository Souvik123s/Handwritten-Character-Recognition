{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import resize\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, img = cv2.threshold(grayImage,127,255,cv2.THRESH_BINARY)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_images_from_folder(\"C:/Users/LENOVO/project/newdataset\")\n",
    "images=[]\n",
    "for img in dataset:\n",
    "    c=resize(img, (28, 28), mode='constant', cval=1.0, clip=True)\n",
    "    c=c.flatten()\n",
    "    images.append(c)\n",
    "dataset=images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel (r'C:\\Users\\LENOVO\\project\\newdataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A'],\n",
       "       ['A'],\n",
       "       ['A'],\n",
       "       ...,\n",
       "       ['Z'],\n",
       "       ['Z'],\n",
       "       ['Z']], dtype='<U1')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels=np.array(df)\n",
    "labels=Labels.astype(np.str)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset, labels, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "verbose_classifiers = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = StandardScaler().fit(X_train)\n",
    "X_pca_train = Scaler.transform(X_train)\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_pca_train)\n",
    "P_train = pca.transform(X_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_test = Scaler.transform(X_test)\n",
    "P_test = pca.transform(X_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier_PCA = MLPClassifier(hidden_layer_sizes=(300,400,150), max_iter=5000, tol=0.0001, random_state=1, verbose=verbose_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(300,400,300), max_iter=5000, tol=0.0001, random_state=1, verbose=verbose_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.73846694\n",
      "Iteration 2, loss = 1.67394753\n",
      "Iteration 3, loss = 1.18683629\n",
      "Iteration 4, loss = 0.91333516\n",
      "Iteration 5, loss = 0.73918778\n",
      "Iteration 6, loss = 0.62316575\n",
      "Iteration 7, loss = 0.52693719\n",
      "Iteration 8, loss = 0.44707010\n",
      "Iteration 9, loss = 0.39399727\n",
      "Iteration 10, loss = 0.34963924\n",
      "Iteration 11, loss = 0.32281156\n",
      "Iteration 12, loss = 0.29427907\n",
      "Iteration 13, loss = 0.28045339\n",
      "Iteration 14, loss = 0.26061393\n",
      "Iteration 15, loss = 0.24851108\n",
      "Iteration 16, loss = 0.24457061\n",
      "Iteration 17, loss = 0.24489742\n",
      "Iteration 18, loss = 0.23808908\n",
      "Iteration 19, loss = 0.23174224\n",
      "Iteration 20, loss = 0.22245123\n",
      "Iteration 21, loss = 0.21489305\n",
      "Iteration 22, loss = 0.21063054\n",
      "Iteration 23, loss = 0.21365780\n",
      "Iteration 24, loss = 0.19805225\n",
      "Iteration 25, loss = 0.19098455\n",
      "Iteration 26, loss = 0.19040714\n",
      "Iteration 27, loss = 0.19091133\n",
      "Iteration 28, loss = 0.18669829\n",
      "Iteration 29, loss = 0.18442904\n",
      "Iteration 30, loss = 0.18236390\n",
      "Iteration 31, loss = 0.17454531\n",
      "Iteration 32, loss = 0.17381073\n",
      "Iteration 33, loss = 0.16557244\n",
      "Iteration 34, loss = 0.16781258\n",
      "Iteration 35, loss = 0.17692179\n",
      "Iteration 36, loss = 0.16844172\n",
      "Iteration 37, loss = 0.17064737\n",
      "Iteration 38, loss = 0.16398617\n",
      "Iteration 39, loss = 0.15954325\n",
      "Iteration 40, loss = 0.16666182\n",
      "Iteration 41, loss = 0.15930785\n",
      "Iteration 42, loss = 0.15561759\n",
      "Iteration 43, loss = 0.15200584\n",
      "Iteration 44, loss = 0.15433680\n",
      "Iteration 45, loss = 0.14884080\n",
      "Iteration 46, loss = 0.15504432\n",
      "Iteration 47, loss = 0.15969720\n",
      "Iteration 48, loss = 0.15402174\n",
      "Iteration 49, loss = 0.14721257\n",
      "Iteration 50, loss = 0.14524261\n",
      "Iteration 51, loss = 0.14590747\n",
      "Iteration 52, loss = 0.14357554\n",
      "Iteration 53, loss = 0.13766014\n",
      "Iteration 54, loss = 0.14247884\n",
      "Iteration 55, loss = 0.13984411\n",
      "Iteration 56, loss = 0.13815687\n",
      "Iteration 57, loss = 0.14707051\n",
      "Iteration 58, loss = 0.15410225\n",
      "Iteration 59, loss = 0.14773663\n",
      "Iteration 60, loss = 0.14026411\n",
      "Iteration 61, loss = 0.13559411\n",
      "Iteration 62, loss = 0.13457713\n",
      "Iteration 63, loss = 0.13498980\n",
      "Iteration 64, loss = 0.13033368\n",
      "Iteration 65, loss = 0.13054033\n",
      "Iteration 66, loss = 0.13048133\n",
      "Iteration 67, loss = 0.13284516\n",
      "Iteration 68, loss = 0.12773785\n",
      "Iteration 69, loss = 0.13146642\n",
      "Iteration 70, loss = 0.13104616\n",
      "Iteration 71, loss = 0.13280635\n",
      "Iteration 72, loss = 0.12880773\n",
      "Iteration 73, loss = 0.12539976\n",
      "Iteration 74, loss = 0.12635169\n",
      "Iteration 75, loss = 0.12764965\n",
      "Iteration 76, loss = 0.12575506\n",
      "Iteration 77, loss = 0.12550051\n",
      "Iteration 78, loss = 0.12731652\n",
      "Iteration 79, loss = 0.12308360\n",
      "Iteration 80, loss = 0.12552350\n",
      "Iteration 81, loss = 0.11976020\n",
      "Iteration 82, loss = 0.11985907\n",
      "Iteration 83, loss = 0.12077555\n",
      "Iteration 84, loss = 0.12600234\n",
      "Iteration 85, loss = 0.12070768\n",
      "Iteration 86, loss = 0.11860693\n",
      "Iteration 87, loss = 0.11797207\n",
      "Iteration 88, loss = 0.11792318\n",
      "Iteration 89, loss = 0.11523688\n",
      "Iteration 90, loss = 0.11637068\n",
      "Iteration 91, loss = 0.11408814\n",
      "Iteration 92, loss = 0.11571400\n",
      "Iteration 93, loss = 0.11601762\n",
      "Iteration 94, loss = 0.11599426\n",
      "Iteration 95, loss = 0.11861565\n",
      "Iteration 96, loss = 0.11701665\n",
      "Iteration 97, loss = 0.12501943\n",
      "Iteration 98, loss = 0.11802911\n",
      "Iteration 99, loss = 0.12209575\n",
      "Iteration 100, loss = 0.11840002\n",
      "Iteration 101, loss = 0.11550329\n",
      "Iteration 102, loss = 0.11762163\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(300, 400, 150), max_iter=5000, random_state=1,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_classifier_PCA.fit(P_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_prediction_PCA = mlp_classifier_PCA.predict(P_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.68416300\n",
      "Iteration 2, loss = 1.88422811\n",
      "Iteration 3, loss = 1.52474001\n",
      "Iteration 4, loss = 1.26186820\n",
      "Iteration 5, loss = 1.07349759\n",
      "Iteration 6, loss = 0.97622823\n",
      "Iteration 7, loss = 0.89125523\n",
      "Iteration 8, loss = 0.77532930\n",
      "Iteration 9, loss = 0.69664631\n",
      "Iteration 10, loss = 0.61457503\n",
      "Iteration 11, loss = 0.57916135\n",
      "Iteration 12, loss = 0.53916379\n",
      "Iteration 13, loss = 0.47461259\n",
      "Iteration 14, loss = 0.40053290\n",
      "Iteration 15, loss = 0.35539266\n",
      "Iteration 16, loss = 0.32337003\n",
      "Iteration 17, loss = 0.29867076\n",
      "Iteration 18, loss = 0.26100565\n",
      "Iteration 19, loss = 0.23080077\n",
      "Iteration 20, loss = 0.22642891\n",
      "Iteration 21, loss = 0.21313079\n",
      "Iteration 22, loss = 0.21149500\n",
      "Iteration 23, loss = 0.20303879\n",
      "Iteration 24, loss = 0.18697604\n",
      "Iteration 25, loss = 0.18049497\n",
      "Iteration 26, loss = 0.17868363\n",
      "Iteration 27, loss = 0.16568791\n",
      "Iteration 28, loss = 0.16101094\n",
      "Iteration 29, loss = 0.15880836\n",
      "Iteration 30, loss = 0.19423842\n",
      "Iteration 31, loss = 0.17619279\n",
      "Iteration 32, loss = 0.17487504\n",
      "Iteration 33, loss = 0.16137502\n",
      "Iteration 34, loss = 0.14876240\n",
      "Iteration 35, loss = 0.14586467\n",
      "Iteration 36, loss = 0.15240753\n",
      "Iteration 37, loss = 0.15424513\n",
      "Iteration 38, loss = 0.18731955\n",
      "Iteration 39, loss = 0.15830791\n",
      "Iteration 40, loss = 0.15177922\n",
      "Iteration 41, loss = 0.14942887\n",
      "Iteration 42, loss = 0.15527776\n",
      "Iteration 43, loss = 0.14390960\n",
      "Iteration 44, loss = 0.14454805\n",
      "Iteration 45, loss = 0.13431445\n",
      "Iteration 46, loss = 0.14054926\n",
      "Iteration 47, loss = 0.13886019\n",
      "Iteration 48, loss = 0.13723046\n",
      "Iteration 49, loss = 0.13462592\n",
      "Iteration 50, loss = 0.13530897\n",
      "Iteration 51, loss = 0.13240823\n",
      "Iteration 52, loss = 0.12415259\n",
      "Iteration 53, loss = 0.12739841\n",
      "Iteration 54, loss = 0.12077925\n",
      "Iteration 55, loss = 0.12997470\n",
      "Iteration 56, loss = 0.12033688\n",
      "Iteration 57, loss = 0.11926627\n",
      "Iteration 58, loss = 0.12173045\n",
      "Iteration 59, loss = 0.12040937\n",
      "Iteration 60, loss = 0.12354626\n",
      "Iteration 61, loss = 0.12551121\n",
      "Iteration 62, loss = 0.11814920\n",
      "Iteration 63, loss = 0.11883143\n",
      "Iteration 64, loss = 0.11830525\n",
      "Iteration 65, loss = 0.12008560\n",
      "Iteration 66, loss = 0.11716121\n",
      "Iteration 67, loss = 0.11654257\n",
      "Iteration 68, loss = 0.11868518\n",
      "Iteration 69, loss = 0.11580795\n",
      "Iteration 70, loss = 0.10864520\n",
      "Iteration 71, loss = 0.11127376\n",
      "Iteration 72, loss = 0.11573199\n",
      "Iteration 73, loss = 0.11208587\n",
      "Iteration 74, loss = 0.11681347\n",
      "Iteration 75, loss = 0.12418688\n",
      "Iteration 76, loss = 0.11645202\n",
      "Iteration 77, loss = 0.11585755\n",
      "Iteration 78, loss = 0.11559382\n",
      "Iteration 79, loss = 0.12708352\n",
      "Iteration 80, loss = 0.12005755\n",
      "Iteration 81, loss = 0.11985510\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(300, 400, 300), max_iter=5000, random_state=1,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for img in X_test:\n",
    "    test.append(img.flatten())\n",
    "result=mlp_classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882 605\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(0,len(mlp_prediction_PCA)):\n",
    "    if mlp_prediction_PCA[i]==Y_test[i]:\n",
    "        count=count+1\n",
    "print(len(mlp_prediction_PCA),count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882 605\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(0,len(result)):\n",
    "    if mlp_prediction_PCA[i]==Y_test[i]:\n",
    "        count=count+1\n",
    "print(len(result),count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v x12345bng6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
